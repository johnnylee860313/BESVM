{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code normalize the dataset before adding err,the err are come from normalized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jupyter_Importer\n",
    "from MLModels_FeatureImportance import featureImportance_linearRegression\n",
    "from MLModels_FeatureImportance import featureImportance_permutation\n",
    "from MLModels_FeatureImportance import featureImportance_DTree\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date</td>\n",
       "      <td>Temperature</td>\n",
       "      <td>Humidity</td>\n",
       "      <td>Light</td>\n",
       "      <td>CO2</td>\n",
       "      <td>HumidityRatio</td>\n",
       "      <td>Occupancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-02 14:19:00</td>\n",
       "      <td>23.7</td>\n",
       "      <td>26.272</td>\n",
       "      <td>585.2</td>\n",
       "      <td>749.2</td>\n",
       "      <td>0.0047641630241641</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-02 14:19:59</td>\n",
       "      <td>23.718</td>\n",
       "      <td>26.29</td>\n",
       "      <td>578.4</td>\n",
       "      <td>760.4</td>\n",
       "      <td>0.0047726609921251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-02 14:21:00</td>\n",
       "      <td>23.73</td>\n",
       "      <td>26.23</td>\n",
       "      <td>572.666666666667</td>\n",
       "      <td>769.666666666667</td>\n",
       "      <td>0.0047651525524654</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-02 14:22:00</td>\n",
       "      <td>23.7225</td>\n",
       "      <td>26.125</td>\n",
       "      <td>493.75</td>\n",
       "      <td>774.75</td>\n",
       "      <td>0.0047437733559968</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    x1           x2        x3                x4  \\\n",
       "0                 date  Temperature  Humidity             Light   \n",
       "1  2015-02-02 14:19:00         23.7    26.272             585.2   \n",
       "2  2015-02-02 14:19:59       23.718     26.29             578.4   \n",
       "3  2015-02-02 14:21:00        23.73     26.23  572.666666666667   \n",
       "4  2015-02-02 14:22:00      23.7225    26.125            493.75   \n",
       "\n",
       "                 x5                  x6          y  \n",
       "0               CO2       HumidityRatio  Occupancy  \n",
       "1             749.2  0.0047641630241641          1  \n",
       "2             760.4  0.0047726609921251          1  \n",
       "3  769.666666666667  0.0047651525524654          1  \n",
       "4            774.75  0.0047437733559968          1  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Occupancy.csv\", names = ['x' + str(i) for i in range(1, 7)] + ['y'], sep = \",\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>585.200000</td>\n",
       "      <td>749.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>578.400000</td>\n",
       "      <td>760.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572.666667</td>\n",
       "      <td>769.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>493.750000</td>\n",
       "      <td>774.750000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>488.600000</td>\n",
       "      <td>779.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20556</th>\n",
       "      <td>429.750000</td>\n",
       "      <td>1505.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20557</th>\n",
       "      <td>423.500000</td>\n",
       "      <td>1514.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20558</th>\n",
       "      <td>423.500000</td>\n",
       "      <td>1521.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20559</th>\n",
       "      <td>418.750000</td>\n",
       "      <td>1632.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20560</th>\n",
       "      <td>409.000000</td>\n",
       "      <td>1864.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20560 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x1           x2  y\n",
       "1      585.200000   749.200000  1\n",
       "2      578.400000   760.400000  1\n",
       "3      572.666667   769.666667  1\n",
       "4      493.750000   774.750000  1\n",
       "5      488.600000   779.000000  1\n",
       "...           ...          ... ..\n",
       "20556  429.750000  1505.250000  1\n",
       "20557  423.500000  1514.500000  1\n",
       "20558  423.500000  1521.500000  1\n",
       "20559  418.750000  1632.000000  1\n",
       "20560  409.000000  1864.000000  1\n",
       "\n",
       "[20560 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_light_co2 = dataset.iloc[1:,3:5]\n",
    "dataset_light_co2['y'] = dataset.iloc[1:,6:7]\n",
    "dataset_light_co2.columns = ['x1','x2','y']\n",
    "dataset_light_co2['x1'] = dataset_light_co2['x1'].apply(lambda x : float(x))\n",
    "dataset_light_co2['x2'] = dataset_light_co2['x2'].apply(lambda x : float(x))\n",
    "dataset_light_co2['y'] = dataset_light_co2['y'].apply(lambda x : int(x))\n",
    "dataset_light_co2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24] [24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6757 entries, 1 to 20560\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      6757 non-null   float64\n",
      " 1   x2      6757 non-null   float64\n",
      " 2   y       6757 non-null   int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 211.2 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4112 entries, 8855 to 4674\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      4112 non-null   float64\n",
      " 1   x2      4112 non-null   float64\n",
      " 2   y       4112 non-null   int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 128.5 KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "subset = dataset_light_co2.sample(frac=0.2,replace=False,random_state=43)\n",
    "dataset_light_co2 = dataset_light_co2.append(subset)\n",
    "dataset_light_co2 = dataset_light_co2.drop_duplicates(subset=['x1','x2','y'],keep=False)\n",
    "\n",
    "subsample_x = subset.iloc[:,:-1].values\n",
    "subsample_y = subset.iloc[:,-1].values\n",
    "\n",
    "#from 0-24 means angle\n",
    "error_a = []\n",
    "error_b = []\n",
    "for i in range(0,25) :\n",
    "    error_a.append(i)\n",
    "    error_b.append(24-i)\n",
    "\n",
    "print(error_a,error_b)\n",
    "print(dataset_light_co2.info(),subset.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RegCoef : [0.001715115813006853, 0.0001540538185663689]\n",
      "importanceReg : [0.9175816812106525, 0.08241831878934744]\n",
      "PermuCoef : [0.297227626459144, 0.061867704280155644]\n",
      "importancePermu : [0.8277123120682649, 0.17228768793173505]\n",
      "DTreeCoef : [0.9583616917154414, 0.04163830828455862]\n",
      "importanceDTree : [0.9583616917154414, 0.04163830828455862]\n"
     ]
    }
   ],
   "source": [
    "importanceReg,RegCoef = featureImportance_linearRegression(subsample_x,subsample_y)\n",
    "model = KNeighborsClassifier(n_neighbors=5,algorithm=\"brute\")  \n",
    "model.fit(subsample_x,subsample_y)  \n",
    "importancePermu,PermuCoef = featureImportance_permutation(model,subsample_x,subsample_y)\n",
    "importanceDTree,DTreeCoef = featureImportance_DTree(subsample_x,subsample_y)\n",
    "print(\"RegCoef : \" +str(RegCoef))\n",
    "print(\"importanceReg : \"+str(importanceReg))\n",
    "print(\"PermuCoef : \"+str(PermuCoef))\n",
    "print(\"importancePermu : \"+str(importancePermu))\n",
    "print(\"DTreeCoef : \" +str(DTreeCoef))\n",
    "print(\"importanceDTree : \"+str(importanceDTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6757 entries, 1 to 20560\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      6757 non-null   float64\n",
      " 1   x2      6757 non-null   float64\n",
      " 2   y       6757 non-null   int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 211.2 KB\n",
      "[[ 1.25479257 -0.28289817]\n",
      " [ 0.82754835 -0.19627606]\n",
      " [ 1.18166864 -0.16430146]\n",
      " ...\n",
      " [ 0.53962291  1.96200951]\n",
      " [ 0.51861452  2.28320892]\n",
      " [ 0.47549205  2.95758232]] None\n"
     ]
    }
   ],
   "source": [
    "#preprocess the data\n",
    "dataset_light_co2_nml = dataset_light_co2.iloc[:,:-1]\n",
    "dataset_light_co2_nml = preprocessing.scale(dataset_light_co2_nml)\n",
    "print(dataset_light_co2_nml,dataset_light_co2.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1    5.659035\n",
      "x2    3.575273\n",
      "y     1.000000\n",
      "dtype: float64 x1   -1.333440\n",
      "x2   -1.260885\n",
      "y     0.000000\n",
      "dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6757 entries, 0 to 6756\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      6757 non-null   float64\n",
      " 1   x2      6757 non-null   float64\n",
      " 2   y       2452 non-null   float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 158.5 KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6757 entries, 1 to 20560\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      6757 non-null   float64\n",
      " 1   x2      6757 non-null   float64\n",
      " 2   y       6757 non-null   int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 469.2 KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "dataset_light_co2_nml = pd.DataFrame(dataset_light_co2_nml)\n",
    "dataset_light_co2_nml.columns = ['x1','x2']\n",
    "#dataset_light_co2_nml['y'] = dataset_light_co2['y'].copy()\n",
    "dataset_light_co2_nml.insert(2,'y',dataset_light_co2['y'])\n",
    "\n",
    "x1_min = -1.333440\n",
    "x1_max = 5.659035\n",
    "x2_min = -1.260885\n",
    "x2_max = 3.575273\n",
    "print(dataset_light_co2_nml.max(),dataset_light_co2_nml.min())\n",
    "print(dataset_light_co2_nml.info(),dataset_light_co2.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding err by the normalized data\n",
    "#bound the value between min and max\n",
    "\n",
    "def df_2feature_be_generates(BE,i,n,importance=importanceReg,df=dataset_light_co2_nml.copy()) :#i = 1 for brute force iteration,n = 1for negative importance\n",
    "    temp = dataset_light_co2_nml.copy()\n",
    "    angle = 0 #0 for normal case ,1 for adding error with cos sin\n",
    "    #switch = {1:func1,2:func2}\n",
    "    #temp = df.copy()\n",
    "    df_2feature_be = pd.DataFrame.to_numpy(dataset_light_co2_nml)\n",
    "    #df_2feature_be = pd.DataFrame.to_numpy(df)\n",
    "    \n",
    "    if i >= 0 and n == 0 :\n",
    "        angle = 1\n",
    "        e1 = temp['x1'].mean()*BE*math.cos((error_a[i]/(error_a[i]+error_b[i])))\n",
    "        e2 = temp['x2'].mean()*BE*math.sin((error_b[i]/(error_a[i]+error_b[i])))\n",
    "    elif i == -1 and n == 1:\n",
    "        angle = 0\n",
    "        e1 = temp['x1'].mean()*BE*importance[0]\n",
    "        e2 = temp['x2'].mean()*BE*importance[1]\n",
    "    elif i == -1 and n == 0 :\n",
    "        angle = 0\n",
    "        e1 = temp['x1'].mean()*BE*importance[1]\n",
    "        e2 = temp['x2'].mean()*BE*importance[0]\n",
    "    \n",
    "\n",
    "    if angle == 0:\n",
    "        for idx,cell in temp['x1'].iteritems():\n",
    "            temp['x1'][idx] += e1\n",
    "            if temp['x1'][idx] > x1_max:\n",
    "                temp['x1'][idx] = x1_max\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "\n",
    "        for idx,cell in temp['x1'].iteritems():\n",
    "            temp['x1'][idx] = temp['x1'][idx] - e1\n",
    "            if temp['x1'][idx] < x1_min:\n",
    "                temp['x1'][idx] = x1_min\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "\n",
    "        for idx,cell in temp['x2'].iteritems():\n",
    "            temp['x2'][idx] += e2\n",
    "            if temp['x2'][idx] > x2_max:\n",
    "                temp['x2'][idx] = x2_max\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "\n",
    "        for idx,cell in temp['x2'].iteritems():\n",
    "            temp['x2'][idx] = temp['x2'][idx] - e2\n",
    "            if temp['x2'][idx] < x2_min:\n",
    "                temp['x2'][idx] = x2_min\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "\n",
    "        df_2feature_be = pd.DataFrame(df_2feature_be)\n",
    "        #print(df_2feature_be)\n",
    "\n",
    "    elif angle == 1:\n",
    "        for idx,cell in temp['x1'].iteritems():\n",
    "            temp['x1'][idx] += e1\n",
    "            if temp['x1'][idx] > x1_max:\n",
    "                temp['x1'][idx] = x1_max\n",
    "            if temp['x1'][idx] < x1_min:\n",
    "                temp['x1'][idx] = x1_min\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "\n",
    "        for idx,cell in temp['x2'].iteritems():\n",
    "            temp['x2'][idx] += e2\n",
    "            if temp['x2'][idx] > x2_max:\n",
    "                temp['x2'][idx] = x2_max\n",
    "            if temp['x2'][idx] < x2_min:\n",
    "                temp['x2'][idx] = x2_min\n",
    "        temp = temp.to_numpy()\n",
    "        df_2feature_be = np.vstack((df_2feature_be,temp))\n",
    "        #print(df_2feature_be.shape)\n",
    "        temp = dataset_light_co2_nml.copy()\n",
    "        \n",
    "        df_2feature_be = pd.DataFrame(df_2feature_be)\n",
    "\n",
    "    \n",
    "\n",
    "    return df_2feature_be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [33785, 6757]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21276\\66182757.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_be\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_2feature_be\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_be\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_light_co2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_be\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_be\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mclf_BE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf_BE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\BESVM\\BESVM\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2415\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2417\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\BESVM\\BESVM\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\BESVM\\BESVM\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    332\u001b[0m         raise ValueError(\n\u001b[0;32m    333\u001b[0m             \u001b[1;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m             \u001b[1;33m%\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m         )\n\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [33785, 6757]"
     ]
    }
   ],
   "source": [
    "#using importanceReg as error allocation rate to predict by svm\n",
    "BE = 0.2\n",
    "df_2feature_be = df_2feature_be_generates(BE,-1,0,importanceReg)\n",
    "x_be = df_2feature_be.values\n",
    "y_be = dataset_light_co2.iloc[:,-1].values\n",
    "X_train,X_test,y_train, y_test = train_test_split(x_be, y_be, test_size=0.2,random_state=1)\n",
    "clf_BE = SVC(kernel='linear',C=1,gamma='auto')\n",
    "clf_BE.fit(X_train, y_train)\n",
    "y_BE_predict = clf_BE.predict(X_test)\n",
    "result_BE_train = clf_BE.score(X_train, y_train)\n",
    "result_BE_test = clf_BE.score(X_test, y_test)\n",
    "subset_raw = clf_BE.score(subsample_x, subsample_y)\n",
    "print('BESVM Accuracy (on training) = with x1 bounded error ('+str(BE)+'%*'+str(importanceReg[1])+'),x2 with error ('+str(BE)+'%*'+str(importanceReg[0])+') : '+str(result_BE_train))\n",
    "print('BESVM Accuracy (on testing) = with x1 bounded error ('+str(BE)+'%*'+str(importanceReg[1])+'),x2 with error ('+str(BE)+'%*'+str(importanceReg[0])+') : '+str(result_BE_test))\n",
    "print('BESVM Accuracy (on subset_raw) = with no bounded error,x2 with no error '+str(subset_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using importancePermu as error allocation rate to predict by svm\n",
    "df_2feature_be = df_2feature_be_generates(BE,-1,0,importancePermu)\n",
    "x_be = df_2feature_be.iloc[:, :-1].values\n",
    "y_be = df_2feature_be.iloc[:,-1].values\n",
    "X_train,X_test,y_train, y_test = train_test_split(x_be, y_be, test_size=0.2,random_state=1)\n",
    "clf_BE = SVC(kernel='linear',C=1,gamma='auto')\n",
    "clf_BE.fit(X_train, y_train)\n",
    "y_BE_predict = clf_BE.predict(X_test)\n",
    "result_BE_train = clf_BE.score(X_train, y_train)\n",
    "result_BE_test = clf_BE.score(X_test, y_test)\n",
    "subset_raw = clf_BE.score(subsample_x, subsample_y)\n",
    "print('BESVM Accuracy (on training) = with x1 bounded error ('+str(BE)+'%*'+str(importancePermu[1])+'),x2 with error ('+str(BE)+'%*'+str(importancePermu[0])+') : '+str(result_BE_train))\n",
    "print('BESVM Accuracy (on testing) = with x1 bounded error ('+str(BE)+'%*'+str(importancePermu[1])+'),x2 with error ('+str(BE)+'%*'+str(importancePermu[0])+') : '+str(result_BE_test))\n",
    "print('BESVM Accuracy (on subset_raw) = with no bounded error,x2 with no error '+str(subset_raw))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "823264832876f692eb60ba3c01443ddcf5448cec612e602318bd1dc48bf5d5c1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
